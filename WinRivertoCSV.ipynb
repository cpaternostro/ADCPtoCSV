{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import datetime as dtt\n",
    "# import xarray as xr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#read in all files with acii extension\n",
    "ascii_files = glob.glob('*ASC*')\n",
    "ascii_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#create list of columns, the += is appending the other lists\n",
    "columns = ['datetime', 'ensemble_number', 'number_of_ensembles', \n",
    "           'pitch', 'roll', 'corrected_heading', 'adcp_temp']\n",
    "columns += ['v_bt_x', 'v_bt_y', 'v_bt_z', 'v_bt_err', \n",
    "            'depth_snd', 'gga_alt', 'gga_dalt', 'gga_hdop',\n",
    "            'depth_beam1', 'depth_beam2', 'depth_beam3', 'depth_beam4']\n",
    "columns += ['total_elapsed_dist', 'total_elapsed_time', 'total_dist_n', 'total_dist_e', 'total_dist_mg']\n",
    "columns += ['lat', 'lon', 'invalid', 'fixed_value_not_used']\n",
    "columns += ['Q_middle', 'Q_top', 'Q_bot', \n",
    "            'start_shore_dist_est', 'start_dist', 'end_shore_dist_est', 'end_dist',\n",
    "            'start_depth', 'end_depth']\n",
    "columns += ['nbins', 'unit', 'vel_ref', 'intensity_units', 'intensity_scale_fac', 'sound_abs_fac']\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of columns for df\n",
    "df_cols = ['depth', 'vmag', 'vdir', 'vx', 'vy', 'vz', 'verr', 'bs1', 'bs2', 'bs3', 'bs4', 'pctg', 'Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_header(f):\n",
    "    #go through each row of the header, strips each piece and splits it from the rest\n",
    "    row1 = next(f).strip().split()\n",
    "    #checks if '20' is in the first row - i guess this is a marker for header info\n",
    "    row1[0] = '20' + row1[0] if '20' not in row1[0] else row1[0]\n",
    "    #in rows from start to row 6, convert to datetime\n",
    "    dt = pd.datetime(*tuple(map(int, row1[:6])), int(int(row1[6]) * 1e4))\n",
    "    #convert to another type of datetime (pandas to numpy)\n",
    "    dt64 = np.datetime64(dt)\n",
    "    #converts ensemble number to integer rows 7-9, maps this conversion to row 7-9\n",
    "    ensemble_number, ne = map(int, row1[7:9])\n",
    "    # concatenate datetime, ensembe number, and converts rows 9-end to be a float list\n",
    "    data = [dt] + [ensemble_number, ne] + list(map(float, row1[9:]))\n",
    "    #loops through range 0-4, appends next row (strip and split probably because dilemeter might change throughout)\n",
    "    for i in range(4):\n",
    "        #appends next row, converts to float\n",
    "        #strip and split probably because dilemeter might change throughout\n",
    "        data += list(map(float, next(f).strip().split()))\n",
    "    #reassigns row 6, strips and splits it\n",
    "    row6 = next(f).strip().split()\n",
    "    #number of bins is integer of row6\n",
    "    nbins = int(row6[0])\n",
    "    #appends row 6 items 1-4 to data\n",
    "    data += row6[1:4]\n",
    "    #appends and converts to float items in 4-end in row 6\n",
    "    data += list(map(float, row6[4:]))\n",
    "    #returns ensumber number, data lsit, nbins, and datetime\n",
    "    return ensemble_number, data, nbins, dt\n",
    "\n",
    "def ascii2pd(ascii_file, make_geometries=False):\n",
    "    # f is ascii file\n",
    "    f = open(ascii_file)\n",
    "    while True:\n",
    "        #while there is a file to open, goes through each line, strips each line and splits it from the rest\n",
    "        line = next(f).strip().split()\n",
    "        #if length of that line is zero, continues to next step\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            #if not, loop breaks\n",
    "            break\n",
    "    #assigns file into to be integer of contents in line\n",
    "    file_info = map(int, line)\n",
    "    #pulls out each of these variables from file_info - order matters\n",
    "    depth_cell_len, blank_after_transmit, adcp_depth_from_cn, n_depth_cells, n_pings, dt, mode = file_info\n",
    "    \n",
    "    #create two empty dictionaries\n",
    "    data = {}\n",
    "    dfs = {}\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            #while all conditions are true, run parse_header function to get\n",
    "            # ensemble number, data, nbins, and datetime in that order\n",
    "            n, d, nbins, dt = parse_header(f)\n",
    "            # data[n] is assigned to data (d is panel)\n",
    "            data[n] = d\n",
    "            #creates a pandas dataframe and assigns column names\n",
    "            df = pd.DataFrame([map(float, next(f).strip().split()) for b in range(nbins)], columns=df_cols)\n",
    "            #df.index = df.depth\n",
    "            #dfs[dt] (dataframe at some timestamp) is assigned by df in the dfs dictionary\n",
    "            #timestamp is the key to access each part of the dictionary\n",
    "            dfs[dt] = df\n",
    "    #if there is stopiteration error, pass avoids code breaking\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    #creates pandas dataframe from the data dictionary, orients the data by index (datetime)\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    #assigns df columns to the column list created above\n",
    "    df.columns = columns\n",
    "    #converts string of datetime indices to datetime\n",
    "    df.index = pd.to_datetime(df.datetime)\n",
    "    #creates a geometry by grabbing lat and lon\n",
    "    if make_geometries:\n",
    "        df['geometry'] = [Point(r.lon, r.lat) for i, r in df.iterrows()]\n",
    "        df['geometry'] = projectdf(df, '+init=epsg:4269', '+init=epsg:26715')\n",
    "        df['X'] = [p.x for p in df.geometry]\n",
    "        df['Y'] = [p.y for p in df.geometry]\n",
    "    else:\n",
    "        df['X'] = df.lon\n",
    "        df['Y'] = df.lat\n",
    "    \n",
    "    # make a data panel of the velocity data\n",
    "    pn = pd.Panel(dfs)\n",
    "    # pn=xr.Dataset(d).to_array()\n",
    "    # pn = xr.DataArray(dfs)\n",
    "    # pn = pn.to_series()\n",
    "    #returns pandas dataframe, dataframe dictionary, and panels\n",
    "    return df, dfs,pn\n",
    "\n",
    "def stack(df, pn, vmin, vmax, freq, make_geometries=False):\n",
    "    #drops nans from each panel along axis one (across columns) and resamples down the indices\n",
    "    #gets the mean and pnr becomes a copy\n",
    "    pnr = pn.dropna(axis=1,how='all').resample(freq, axis=0).mean().copy()\n",
    "    #assigns inds by using loc along all diminsions for veloctity x greater than min and less than max\n",
    "    inds = (pnr.loc[:, :, 'vx'].values < vmin) | (pnr.loc[:, :, 'vx'].values > vmax)\n",
    "    #creates another copy\n",
    "    pnrs = pnr.copy()\n",
    "    #masks data at inds and replaces values inplace for velocity x and y\n",
    "    pnrs.loc[:, :, 'vx'].mask(inds, inplace=True)\n",
    "    pnrs.loc[:, :, 'vy'].mask(inds, inplace=True)\n",
    "    #slice dataframe by X,Y, and datetime, then resamples at variable freq and gets mean\n",
    "    dfr = df[['X', 'Y', 'datetime']].resample(freq).mean()\n",
    "    #if geometries is set to true in the function parameters, creates geometry column in dfr\n",
    "    if make_geometries:\n",
    "        dfr['geometry'] = [Point(r.X, r.Y) for i, r in dfr.iterrows()]\n",
    "    #gets mean of velocity x and y across diminsions (time and ensemble)\n",
    "    dfr['vx'] = pnrs.loc[:, :, 'vx'].mean()\n",
    "    dfr['vy'] = pnrs.loc[:, :, 'vy'].mean()\n",
    "    #drops nans down index\n",
    "    dfr.dropna(axis=0, inplace=True)\n",
    "    #returns resampled dataframe\n",
    "    return dfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in each file and output the results to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "outpath = 'output'\n",
    "if not os.path.isdir(outpath):\n",
    "    os.makedirs(outpath)\n",
    "\n",
    "for ascii_file in ascii_files:\n",
    "    if os.path.getsize(ascii_file) == 0:\n",
    "        continue\n",
    "    print(ascii_file)\n",
    "    df, dfs,pn = ascii2pd(ascii_file)\n",
    "    \n",
    "    # display(pn)\n",
    "    dfr = stack(df, pn, vmin=-1000, vmax=1000, freq='10s')\n",
    "    \n",
    "#     # flatten the panel to a dataframe\n",
    "    dfall = pn.swapaxes(0, 2).to_frame()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataframe of header information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### panel of backscatter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pn.axes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first position.. \":\" is for all timestamps, \n",
    "#second position \":10\" is for everything up to ensemble 10\n",
    "#last position is variable you want - in this case velocity y\n",
    "pn.loc[:, :10., 'vy'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "#plots all timestamps (x) for ensemble numbers 0-10 (y) ,velocity y (value)\n",
    "#vmin and vmax set the limit to the colormap/colorbar\n",
    "plt.imshow(pn.loc[:, :10., 'vy'], vmin=-10, vmax=10) #, interpolation='None') #commented out interp.. looks smoother\n",
    "plt.gca().set_aspect(100)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process single ADCP panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vmin, vmax = -1000, 1000 # valid range of velocities\n",
    "freq = '10s' # resampling frequency\n",
    "\n",
    "#takes panel, drops nans across timestamps, resamples at 10s for each ensemble gets mean and makes copy\n",
    "pnr = pn.dropna(axis=1, how='all').resample(freq, axis=0).mean().copy()\n",
    "#create inds for finding velocity x <min, >max for all timestamps and ensembles\n",
    "inds = (pnr.loc[:, :, 'vx'].values < vmin) | (pnr.loc[:, :, 'vx'].values > vmax)\n",
    "#make copy\n",
    "pnrs = pnr.copy()\n",
    "#apply mask to all timestamps and ensembles for velocity x and y and do it inplace\n",
    "pnrs.loc[:, :, 'vx'].mask(inds, inplace=True)\n",
    "pnrs.loc[:, :, 'vy'].mask(inds, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#create backscatter variable\n",
    "#all timestamps, ensemble 0-10, takes mean for all backscatter variables on resampled panel\n",
    "bs = pnr.loc[:, :10, ['bs1', 'bs2', 'bs3', 'bs4']].mean(axis=2)\n",
    "#all timestamps, ensemble 0-10, takes mean for all backscatter variables on original panel\n",
    "bs = pn.loc[:, :10, ['bs1', 'bs2', 'bs3', 'bs4']].mean(axis=2)\n",
    "bs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.loc[:, :10, ['bs1', 'bs2', 'bs3', 'bs4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "#creates plot for x(timestampe), y(ensemble), value (mean of backscatter variable in original panel)\n",
    "#if you comment out the second bs variable, you can plot the resampled panel\n",
    "#vmin and vmax set the limit to the colormap/colorbar\n",
    "plt.imshow(bs, vmin=70, vmax=100)\n",
    "plt.gca().set_aspect(100)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot velocity component across panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "#plots x(all timestamps), y(ensemble number 0-10), value (velocity y from resampled panel)\n",
    "#vmin and vmax set the limit to the colormap/colorbar\n",
    "plt.imshow(pnr.loc[:, :10, 'vy'], vmin=-10, vmax=10)\n",
    "plt.gca().set_aspect(5)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "#plots x(all timestamps), y(enemble numer 0-10), value (velocity y from masked resampled panel)\n",
    "#vmin and vmax set the limit to the colormap/colorbar\n",
    "plt.imshow(pnrs.loc[:, :10, 'vy'], vmin=-10, vmax=10)\n",
    "plt.gca().set_aspect(5)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice panel to get dataframe of single measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pn.loc[:'2022-03-03 19', :, 'vy'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduce backscatter panel to dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dfall = pn.swapaxes(0, 2).to_frame()\n",
    "dfall.index.levels[0].name = 'depth_bin'\n",
    "dfall.index.levels[1].name = 'datetime'\n",
    "dfall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write dataframe to csv and then read it back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#     # write the csvs\n",
    "with open('output/{}_alldata.csv'.format(ascii_file), \"w\") as f:\n",
    "    dfall.to_csv(f)  # closes the file because old pands fails to        \n",
    "\n",
    "with open('output/{}_header_info.csv'.format(ascii_file), \"w\") as f:\n",
    "    df.to_csv(f, index=False)\n",
    "# dfr.to_csv('output/{}_{}sampleddata.csv'.format(ascii_file, freq))\n",
    "dfall.to_csv('alldata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall2 = pd.read_csv('alldata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dfall2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write csv of header information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('header_info.csv', index=False) # write it without the index, since it duplicates the datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.13 ('testadcp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c82c6e2e641b19c9062cf8edda36c6455e895c4626c9e07ccfc05d37a2dac272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
